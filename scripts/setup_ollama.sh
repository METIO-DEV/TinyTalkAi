#!/usr/bin/env bash
set -euo pipefail

MODELS=("llama3" "mistral:7b")

is_macos()  { [[ "$OSTYPE" == "darwin"* ]]; }
is_linux()  { [[ "$OSTYPE" == "linux"* ]]; }
is_wsl()    { grep -qi "microsoft" /proc/version 2>/dev/null; }

# -----------------------------------------------------------------------------
# 0. D√©tection plateforme
# -----------------------------------------------------------------------------
if ! is_macos && ! is_linux; then
  echo "ü™ü  Windows d√©tect√© sans WSL¬†: utilisez le conteneur Docker Ollama."
  echo "‚Üí   docker run -d -p 11434:11434 -v ollama-data:/root/.ollama ollama/ollama"
  exit 0
fi

# -----------------------------------------------------------------------------
# 1. Installer Ollama si absent
# -----------------------------------------------------------------------------
if ! command -v ollama &>/dev/null; then
  echo "üîß Installing Ollama CLI‚Ä¶"
  if is_macos; then
    brew install ollama
  else  # Linux ou WSL
    curl -fsSL https://ollama.com/install.sh | sh
    sudo systemctl enable --now ollama
  fi
fi

# -----------------------------------------------------------------------------
# 2. S‚Äôassurer que le daemon tourne
# -----------------------------------------------------------------------------
if ! pgrep -f "ollama serve" &>/dev/null; then
  echo "üöÄ Starting Ollama daemon‚Ä¶"
  if is_macos; then
    brew services start ollama
  else
    sudo systemctl start ollama
  fi
  sleep 3
fi

# -----------------------------------------------------------------------------
# 3. T√©l√©charger les mod√®les manquants
# -----------------------------------------------------------------------------
for model in "${MODELS[@]}"; do
  if ! ollama list | grep -q "$model"; then
    echo "‚¨áÔ∏è  Pulling $model‚Ä¶"
    ollama pull "$model"
  else
    echo "‚úÖ $model already present"
  fi
done

echo "‚úÖ Ollama ready on http://localhost:11434"